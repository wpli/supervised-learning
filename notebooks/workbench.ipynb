{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run this first cell in order to pre-load the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sys.path.append( '../src' )\n",
      "import utils_raw\n",
      "reload( utils_raw )\n",
      "import utils_general\n",
      "reload( utils_general )\n",
      "import utils_preprocess\n",
      "reload( utils_preprocess )\n",
      "import utils_features\n",
      "reload( utils_features )\n",
      "\n",
      "import time\n",
      "import ipdb\n",
      "import sys\n",
      "import collections\n",
      "import numpy\n",
      "from sklearn import linear_model\n",
      "\n",
      "DIST_THRESHOLD = 0.00224946357\n",
      "SQ_DIST_THRESHOLD = DIST_THRESHOLD**2\n",
      "\n",
      "TRAIN_TEST_SPLIT = 0.8\n",
      "\n",
      "if 1:\n",
      "    # ---\n",
      "    # get raw data\n",
      "    sys.stderr.write( \"Getting raw data...\" )\n",
      "\n",
      "    # raw data: pickups\n",
      "    # pickups schema: [ datetime, lon, lat ]\n",
      "\n",
      "\n",
      "    pickups = utils_raw.get_pickups( '../data/pickups_train.csv' )\n",
      "    \n",
      "    # raw data: times/locations that need to be predicted\n",
      "    # times_locations schema: [ prediction_index, start_datetime, end_datetime, lon, lat ] \n",
      "    times_locations = utils_raw.get_times_locations( '../data/test1.txt' )\n",
      "\n",
      "    # set of lon/lats and times that we want pickups for\n",
      "    landmarks = set( [ (i[3], i[4]) for i in times_locations ] )\n",
      "    times = set( i[1].hour for i in times_locations )\n",
      "    sys.stderr.write( \"done.\\n\" )\n",
      "\n",
      "\n",
      "    # ---\n",
      "    # get pre-processed data\n",
      "    sys.stderr.write( \"Pre-processing data...\" )\n",
      "    sys.stderr.write( \"counting pickups by landmarks...\" )\n",
      "    landmark_pickup_dict = utils_preprocess.get_landmark_pickup_dict( landmarks, pickups, SQ_DIST_THRESHOLD )\n",
      "\n",
      "    landmark_time_location_dict = collections.defaultdict( list )\n",
      "    sys.stderr.write( \"counting times by landmarks...\" )\n",
      "    for idx, i in enumerate( times_locations ):\n",
      "        landmark_time_location_dict[(i[3],i[4])].append( idx )\n",
      "        \n",
      "    sys.stderr.write( \"done.\\n\" )\n",
      "\n",
      "    possible_days = list( set( [ i[1].date() for i in times_locations ] ) )\n",
      "    test_days_dict = dict( zip( possible_days, range(len(possible_days) ) ) )\n",
      "\n",
      "    # ---\n",
      "    # create \"raw\" training set and validation set\n",
      "    #landmark_{train|val}_dict[(lon,lat)] = [ ( window_start_datetime0, count0 ), ( window_start_datetime1, count1 ) ... ]\n",
      "    ( landmark_train_dict, landmark_val_dict ) = utils_preprocess.get_train_validation_landmark_dicts( landmark_pickup_dict, pickups, train_test_split = TRAIN_TEST_SPLIT )\n",
      "\n",
      "    # ---\n",
      "    # sample the training set and validation set (possibly to be more reflective of the test set)\n",
      "    sampled_landmark_train_dict = {}\n",
      "    sampled_landmark_val_dict = {}\n",
      "    for landmark, entries in landmark_train_dict.items():\n",
      "        test_start_dts = [ times_locations[idx][1].hour / 2 * 2 for idx in landmark_time_location_dict[landmark] ]\n",
      "        start_time_counts = collections.Counter( test_start_dts )\n",
      "        train_data = [ i for i in landmark_train_dict[landmark] if i[0].hour in start_time_counts ]\n",
      "        sampled_landmark_train_dict[landmark] = [ i for i in landmark_train_dict[landmark] if i[0].hour in start_time_counts ]\n",
      "        sampled_landmark_val_dict[landmark] = [ i for i in landmark_val_dict[landmark] if i[0].hour in start_time_counts ]\n",
      "\n",
      "    all_train_prediction_rms_errors = []\n",
      "    all_val_predictions_rms_errors = []\n",
      "    final_predictions = []"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Getting raw data...done.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Pre-processing data...counting pickups by landmarks...counting times by landmarks..."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "done.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run this cell to add/play around with different functions and write submission files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import ensemble"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "feature_function_list = [ utils_features.feature_day_of_week_binary , \\\n",
      "                              utils_features.feature_time_quadrant_binary, \\\n",
      "                              utils_features.feature_day_time_product_binary, \\\n",
      "                              utils_features.feature_corrected_hour, \\\n",
      "                              utils_features.feature_day, \\\n",
      "                              utils_features.feature_week_number ]\n",
      "    \n",
      "\n",
      "    \n",
      "regression_model = linear_model.Ridge( alpha=0.5 )\n",
      "regression_model = ensemble.RandomForestRegressor()\n",
      "\n",
      "    \n",
      "if 1:\n",
      "    # compute the features on the training set, validation set, and test set\n",
      "    # train model on training set and evaluate performance on training and validation set\n",
      "    # train model on training+validation set and compute predictions on test set                                \n",
      "    for landmark in list( landmarks ):\n",
      "        train_data = sampled_landmark_train_dict[landmark]\n",
      "        val_data = sampled_landmark_val_dict[landmark]\n",
      "        test_data = [ times_locations[idx][1] for idx in landmark_time_location_dict[landmark] ]\n",
      "        test_data_indices = [ times_locations[idx][0] for idx in landmark_time_location_dict[landmark] ]\n",
      "        train_features = numpy.array( [ utils_features.featurize( i[0], feature_function_list, possible_days=possible_days, test_days_dict=test_days_dict ) for i in train_data ] )\n",
      "        train_y = numpy.array( [i[1] for i in train_data ] )\n",
      "        val_features = numpy.array( [ utils_features.featurize( i[0], feature_function_list, possible_days=possible_days, test_days_dict=test_days_dict ) for i in val_data ] )\n",
      "        val_y = numpy.array( [i[1] for i in val_data ] )\n",
      "        \n",
      "        # note that test_data is in a slightly different format than train_data nad val_data because it does not have predictions\n",
      "        test_features = numpy.array( [ utils_features.featurize( i, feature_function_list, possible_days=possible_days, test_days_dict=test_days_dict ) for i in test_data ] )\n",
      "\n",
      "        if len( train_features ) == 0:\n",
      "            test_predictions = [ 0 for i in test_features ]\n",
      "        else:\n",
      "            sys.stderr.write( \"Fitting regression model on training data...\" )\n",
      "            clf = regression_model\n",
      "            clf.fit( train_features, train_y )\n",
      "            # compute performance on training data\n",
      "            predictions = clf.predict( train_features )\n",
      "            predictions = [ max( i,0) for i in predictions ]\n",
      "            all_train_prediction_rms_errors += [ numpy.sqrt((predictions[idx] - train_y[idx])**2) for idx in range(len(predictions)) ]\n",
      "\n",
      "            # compute performance on validation data\n",
      "            predictions = clf.predict( val_features )\n",
      "            predictions = [ max( i, 0 ) for i in predictions ]\n",
      "            all_val_predictions_rms_errors += [ numpy.sqrt((predictions[idx] - val_y[idx])**2) for idx in range(len(predictions)) ]\n",
      "\n",
      "            # train on all of the data\n",
      "            \n",
      "            sys.stderr.write( \"done.\\n\" )\n",
      "                             \n",
      "                    \n",
      "            \n",
      "            full_train_features = numpy.vstack( ( train_features, val_features ) )\n",
      "            full_train_y = numpy.hstack( ( train_y, val_y ) )\n",
      "           \n",
      "            \n",
      "            \n",
      "            \n",
      "            clf = regression_model\n",
      "            clf.fit( full_train_features, full_train_y )\n",
      "            test_predictions = clf.predict( test_features )\n",
      "            \n",
      "            test_predictions = [ max( int( round(i,0) ), 0 ) for i in test_predictions ]\n",
      "            \n",
      "        final_predictions += zip( test_data_indices, test_predictions )\n",
      "        #print clf.coef_[-1], \n",
      "    \n",
      "    sys.stderr.write( \"Average Train RMS Error: \" ) \n",
      "    sys.stderr.write( \"%s\\n\" % numpy.average( all_train_prediction_rms_errors ) )\n",
      "\n",
      "    sys.stderr.write( \"Average Validation RMS Error: \" ) \n",
      "    sys.stderr.write( \"%s\\n\" % numpy.average( all_val_predictions_rms_errors ) )\n",
      "    pickups_guess = dict( final_predictions )\n",
      "\n",
      "    # write to file\n",
      "    extension = str( int( time.time() ) )\n",
      "    final_predictions = pickups_guess.items()\n",
      "    final_predictions.sort( key=lambda x:int(x[0]) )\n",
      "    output_filename = '../submissions/submission.%s.txt' % extension\n",
      "    with open( output_filename, 'w' ) as f:\n",
      "        for i in final_predictions:\n",
      "            f.write( \"%s %s\\n\" %( i[0], str( i[1] ) ) )\n",
      "    \n",
      "    sys.stderr.write( \"Wrote %s.\\n\" % output_filename )\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Average Train RMS Error: 8.58096277605\n",
        "Average Validation RMS Error: 9.54424911815\n",
        "Wrote ../submissions/submission.1387487194.txt.\n"
       ]
      }
     ],
     "prompt_number": 13
    }
   ],
   "metadata": {}
  }
 ]
}